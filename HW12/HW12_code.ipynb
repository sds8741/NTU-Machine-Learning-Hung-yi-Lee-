{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "「hw12_reinforcement_learning_chinese_version.ipynb」的副本",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "92fd902784d3400ab9f1c6b94df238a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d1b7a3d6ae2646548dbdd3483b6d4762",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4752da1585a24067ba964b63901ea25c",
              "IPY_MODEL_3ee4860615ac4fd79e1efa86646dc8c3"
            ]
          }
        },
        "d1b7a3d6ae2646548dbdd3483b6d4762": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4752da1585a24067ba964b63901ea25c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ffc1d8fa701641649855bfc2c98015ef",
            "_dom_classes": [],
            "description": "Total:  280.5, Final:  100.0: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3500,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3500,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_de5eea0fe42c48d3b25e3399a8c155e0"
          }
        },
        "3ee4860615ac4fd79e1efa86646dc8c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7bc941b2f719490e9ad1c5fdd5e4d6ff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3500/3500 [1:10:14&lt;00:00,  1.20s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1b14adfaf93e44a8b2b2b5e3c667d93b"
          }
        },
        "ffc1d8fa701641649855bfc2c98015ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "de5eea0fe42c48d3b25e3399a8c155e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7bc941b2f719490e9ad1c5fdd5e4d6ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1b14adfaf93e44a8b2b2b5e3c667d93b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp30SB4bxeQb"
      },
      "source": [
        "# **Homework 12 - Reinforcement Learning**\n",
        "\n",
        "若有任何問題，歡迎來信至助教信箱 ntu-ml-2021spring-ta@googlegroups.com\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXsnCWPtWSNk"
      },
      "source": [
        "## 前置作業\n",
        "\n",
        "首先我們需要安裝必要的系統套件及 PyPi 套件。\n",
        "gym 這個套件由 OpenAI 所提供，是一套用來開發與比較 Reinforcement Learning 演算法的工具包（toolkit）。\n",
        "而其餘套件則是為了在 Notebook 中繪圖所需要的套件。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e2bScpnkVbv",
        "outputId": "3f0a0353-8afe-4000-e8a3-97d49539d658"
      },
      "source": [
        "!apt update\n",
        "!apt install python-opengl xvfb -y\n",
        "!pip install gym[box2d]==0.18.3 pyvirtualdisplay tqdm numpy==1.19.5 torch==1.8.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [1 In\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [Conn\u001b[0m\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [Conn\u001b[0m\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Connecting to\u001b[0m\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Connecting to\u001b[0m\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,414 kB]\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [480 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [450 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,184 kB]\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,770 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,184 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,616 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [33.5 kB]\n",
            "Get:24 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [906 kB]\n",
            "Get:25 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.9 kB]\n",
            "Fetched 12.4 MB in 4s (2,972 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "46 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libgle3\n",
            "The following NEW packages will be installed:\n",
            "  python-opengl xvfb\n",
            "0 upgraded, 2 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 1,281 kB of archives.\n",
            "After this operation, 7,686 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.9 [784 kB]\n",
            "Fetched 1,281 kB in 1s (977 kB/s)\n",
            "Selecting previously unselected package python-opengl.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting gym[box2d]==0.18.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/db/816fd52c0c196b6799e89d1f65b6c74fead2707cf7d447f3f354edfa7a44/gym-0.18.3.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 8.3MB/s \n",
            "\u001b[?25hCollecting pyvirtualdisplay\n",
            "  Downloading https://files.pythonhosted.org/packages/79/30/e99e0c480a858410757e7516958e149285ea08ed6c9cfe201ed0aa12cee2/PyVirtualDisplay-2.2-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.15,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (1.5.0)\n",
            "Requirement already satisfied: Pillow<=8.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (7.1.2)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (1.3.0)\n",
            "Collecting box2d-py~=2.3.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/34/da5393985c3ff9a76351df6127c275dcb5749ae0abbe8d5210f06d97405d/box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 43.8MB/s \n",
            "\u001b[?25hCollecting EasyProcess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.15,>=1.4.0->gym[box2d]==0.18.3) (0.16.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.18.3-cp37-none-any.whl size=1657528 sha256=254f64425ba9fe58fcfc918ca447afb8a2ea51408165332ef91f2f99ecfc6841\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/c2/4c/2b4c9b85119994837c08315c9415d71008325b7004d385b418\n",
            "Successfully built gym\n",
            "Installing collected packages: box2d-py, gym, EasyProcess, pyvirtualdisplay\n",
            "  Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "Successfully installed EasyProcess-0.3 box2d-py-2.3.8 gym-0.18.3 pyvirtualdisplay-2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_-i3cdoYsks"
      },
      "source": [
        "接下來，設置好 virtual display，並引入所有必要的套件。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl2nREINDLiw"
      },
      "source": [
        "%%capture\n",
        "from pyvirtualdisplay import Display\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVu9-Vdrl4E3"
      },
      "source": [
        "# 請不要更改 random seed !!!!\n",
        "# 不然在judgeboi上 你的成績不會被reproduce !!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV9i8i2YkRbO"
      },
      "source": [
        "seed = 543 # Do not change this\n",
        "def fix(env, seed):\n",
        "  env.seed(seed)\n",
        "  env.action_space.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "  torch.set_deterministic(True)\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He0XDx6bzjgC"
      },
      "source": [
        "最後，引入 OpenAI 的 gym，並建立一個 [Lunar Lander](https://gym.openai.com/envs/LunarLander-v2/) 環境。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_4-xJcbBt09"
      },
      "source": [
        "%%capture\n",
        "import gym\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "env = gym.make('LunarLander-v2')\n",
        "\n",
        "fix(env, seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmiAOfqRwRX5"
      },
      "source": [
        "import time\n",
        "start = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcMjEUWTBEEB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "275c64f9-d81a-42fd-d610-aa7037cacf4c"
      },
      "source": [
        "!pip freeze"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "absl-py==0.12.0\n",
            "alabaster==0.7.12\n",
            "albumentations==0.1.12\n",
            "altair==4.1.0\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==20.1.0\n",
            "arviz==0.11.2\n",
            "astor==0.8.1\n",
            "astropy==4.2.1\n",
            "astunparse==1.6.3\n",
            "async-generator==1.10\n",
            "atari-py==0.2.9\n",
            "atomicwrites==1.4.0\n",
            "attrs==21.2.0\n",
            "audioread==2.1.9\n",
            "autograd==1.3\n",
            "Babel==2.9.1\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==3.3.0\n",
            "blis==0.4.1\n",
            "bokeh==2.3.2\n",
            "Bottleneck==1.3.2\n",
            "box2d-py==2.3.8\n",
            "branca==0.4.2\n",
            "bs4==0.0.1\n",
            "CacheControl==0.12.6\n",
            "cached-property==1.5.2\n",
            "cachetools==4.2.2\n",
            "catalogue==1.0.0\n",
            "certifi==2020.12.5\n",
            "cffi==1.14.5\n",
            "cftime==1.5.0\n",
            "chainer==7.4.0\n",
            "chardet==3.0.4\n",
            "click==7.1.2\n",
            "cloudpickle==1.3.0\n",
            "cmake==3.12.0\n",
            "cmdstanpy==0.9.5\n",
            "colorcet==2.0.6\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.3.2\n",
            "coverage==3.7.1\n",
            "coveralls==0.5\n",
            "crcmod==1.7\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda101==7.4.0\n",
            "cvxopt==1.2.6\n",
            "cvxpy==1.0.31\n",
            "cycler==0.10.0\n",
            "cymem==2.0.5\n",
            "Cython==0.29.23\n",
            "daft==0.0.4\n",
            "dask==2.12.0\n",
            "datascience==0.10.6\n",
            "debugpy==1.0.0\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "descartes==1.1.0\n",
            "dill==0.3.3\n",
            "distributed==1.25.3\n",
            "dlib==19.18.0\n",
            "dm-tree==0.1.6\n",
            "docopt==0.6.2\n",
            "docutils==0.17.1\n",
            "dopamine-rl==1.0.5\n",
            "earthengine-api==0.1.266\n",
            "easydict==1.9\n",
            "EasyProcess==0.3\n",
            "ecos==2.0.7.post1\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm==2.2.5\n",
            "entrypoints==0.3\n",
            "ephem==3.7.7.1\n",
            "et-xmlfile==1.1.0\n",
            "fa2==0.3.5\n",
            "fastai==1.0.61\n",
            "fastdtw==0.3.4\n",
            "fastprogress==1.0.0\n",
            "fastrlock==0.6\n",
            "fbprophet==0.7.1\n",
            "feather-format==0.4.1\n",
            "filelock==3.0.12\n",
            "firebase-admin==4.4.0\n",
            "fix-yahoo-finance==0.0.22\n",
            "Flask==1.1.4\n",
            "flatbuffers==1.12\n",
            "folium==0.8.3\n",
            "future==0.16.0\n",
            "gast==0.4.0\n",
            "GDAL==2.2.2\n",
            "gdown==3.6.4\n",
            "gensim==3.6.0\n",
            "geographiclib==1.50\n",
            "geopy==1.17.0\n",
            "gin-config==0.4.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==1.26.3\n",
            "google-api-python-client==1.12.8\n",
            "google-auth==1.30.0\n",
            "google-auth-httplib2==0.0.4\n",
            "google-auth-oauthlib==0.4.4\n",
            "google-cloud-bigquery==1.21.0\n",
            "google-cloud-bigquery-storage==1.1.0\n",
            "google-cloud-core==1.0.3\n",
            "google-cloud-datastore==1.8.0\n",
            "google-cloud-firestore==1.7.0\n",
            "google-cloud-language==1.2.0\n",
            "google-cloud-storage==1.18.1\n",
            "google-cloud-translate==1.5.0\n",
            "google-colab==1.0.0\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==0.4.1\n",
            "googleapis-common-protos==1.53.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.10.1\n",
            "greenlet==1.1.0\n",
            "grpcio==1.34.1\n",
            "gspread==3.0.1\n",
            "gspread-dataframe==3.0.8\n",
            "gym==0.18.3\n",
            "h5py==3.1.0\n",
            "HeapDict==1.0.1\n",
            "hijri-converter==2.1.1\n",
            "holidays==0.10.5.2\n",
            "holoviews==1.14.3\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.18\n",
            "httplib2==0.17.4\n",
            "httplib2shim==0.0.3\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "ideep4py==2.0.0.post3\n",
            "idna==2.10\n",
            "imageio==2.4.1\n",
            "imagesize==1.2.0\n",
            "imbalanced-learn==0.4.3\n",
            "imblearn==0.0\n",
            "imgaug==0.2.9\n",
            "importlib-metadata==4.0.1\n",
            "importlib-resources==5.1.3\n",
            "imutils==0.5.4\n",
            "inflect==2.1.0\n",
            "iniconfig==1.1.1\n",
            "install==1.3.4\n",
            "intel-openmp==2021.2.0\n",
            "intervaltree==2.1.0\n",
            "ipykernel==4.10.1\n",
            "ipython==5.5.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.6.3\n",
            "itsdangerous==1.1.0\n",
            "jax==0.2.13\n",
            "jaxlib==0.1.66+cuda110\n",
            "jdcal==1.4.1\n",
            "jedi==0.18.0\n",
            "jieba==0.42.1\n",
            "Jinja2==2.11.3\n",
            "joblib==1.0.1\n",
            "jpeg4py==0.1.4\n",
            "jsonschema==2.6.0\n",
            "jupyter==1.0.0\n",
            "jupyter-client==5.3.5\n",
            "jupyter-console==5.2.0\n",
            "jupyter-core==4.7.1\n",
            "jupyterlab-pygments==0.1.2\n",
            "jupyterlab-widgets==1.0.0\n",
            "kaggle==1.5.12\n",
            "kapre==0.3.5\n",
            "Keras==2.4.3\n",
            "keras-nightly==2.5.0.dev2021032900\n",
            "Keras-Preprocessing==1.1.2\n",
            "keras-vis==0.4.1\n",
            "kiwisolver==1.3.1\n",
            "korean-lunar-calendar==0.2.1\n",
            "librosa==0.8.0\n",
            "lightgbm==2.2.3\n",
            "llvmlite==0.34.0\n",
            "lmdb==0.99\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.2.6\n",
            "Markdown==3.3.4\n",
            "MarkupSafe==2.0.1\n",
            "matplotlib==3.2.2\n",
            "matplotlib-inline==0.1.2\n",
            "matplotlib-venn==0.11.6\n",
            "missingno==0.4.2\n",
            "mistune==0.8.4\n",
            "mizani==0.6.0\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==8.7.0\n",
            "moviepy==0.2.3.5\n",
            "mpmath==1.2.1\n",
            "msgpack==1.0.2\n",
            "multiprocess==0.70.11.1\n",
            "multitasking==0.0.9\n",
            "murmurhash==1.0.5\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbclient==0.5.3\n",
            "nbconvert==5.6.1\n",
            "nbformat==5.1.3\n",
            "nest-asyncio==1.5.1\n",
            "netCDF4==1.5.6\n",
            "networkx==2.5.1\n",
            "nibabel==3.0.2\n",
            "nltk==3.2.5\n",
            "notebook==5.3.1\n",
            "numba==0.51.2\n",
            "numexpr==2.7.3\n",
            "numpy==1.19.5\n",
            "nvidia-ml-py3==7.352.0\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.1.0\n",
            "okgrade==0.4.3\n",
            "opencv-contrib-python==4.1.2.30\n",
            "opencv-python==4.1.2.30\n",
            "openpyxl==2.5.9\n",
            "opt-einsum==3.3.0\n",
            "osqp==0.6.2.post0\n",
            "packaging==20.9\n",
            "palettable==3.3.0\n",
            "pandas==1.1.5\n",
            "pandas-datareader==0.9.0\n",
            "pandas-gbq==0.13.3\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.4.3\n",
            "panel==0.11.3\n",
            "param==1.10.1\n",
            "parso==0.8.2\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.1\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==7.1.2\n",
            "pip-tools==4.5.1\n",
            "plac==1.1.3\n",
            "plotly==4.4.1\n",
            "plotnine==0.6.0\n",
            "pluggy==0.7.1\n",
            "pooch==1.3.0\n",
            "portpicker==1.3.9\n",
            "prefetch-generator==1.0.1\n",
            "preshed==3.0.5\n",
            "prettytable==2.1.0\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.10.1\n",
            "promise==2.3\n",
            "prompt-toolkit==1.0.18\n",
            "protobuf==3.12.4\n",
            "psutil==5.4.8\n",
            "psycopg2==2.7.6.1\n",
            "ptyprocess==0.7.0\n",
            "py==1.10.0\n",
            "pyarrow==3.0.0\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycocotools==2.0.2\n",
            "pycparser==2.20\n",
            "pyct==0.4.8\n",
            "pydata-google-auth==1.2.0\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyemd==0.5.1\n",
            "pyerfa==2.0.0\n",
            "pyglet==1.5.0\n",
            "Pygments==2.6.1\n",
            "pygobject==3.26.1\n",
            "pymc3==3.11.2\n",
            "PyMeeus==0.5.11\n",
            "pymongo==3.11.4\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.5\n",
            "pyparsing==2.4.7\n",
            "pyrsistent==0.17.3\n",
            "pysndfile==1.3.8\n",
            "PySocks==1.7.1\n",
            "pystan==2.19.1.1\n",
            "pytest==3.6.4\n",
            "python-apt==0.0.0\n",
            "python-chess==0.23.11\n",
            "python-dateutil==2.8.1\n",
            "python-louvain==0.15\n",
            "python-slugify==5.0.2\n",
            "python-utils==2.5.6\n",
            "pytz==2018.9\n",
            "PyVirtualDisplay==2.2\n",
            "pyviz-comms==2.0.1\n",
            "PyWavelets==1.1.1\n",
            "PyYAML==3.13\n",
            "pyzmq==22.0.3\n",
            "qdldl==0.1.5.post0\n",
            "qtconsole==5.1.0\n",
            "QtPy==1.9.0\n",
            "regex==2019.12.20\n",
            "requests==2.23.0\n",
            "requests-oauthlib==1.3.0\n",
            "resampy==0.2.2\n",
            "retrying==1.3.3\n",
            "rpy2==3.4.4\n",
            "rsa==4.7.2\n",
            "scikit-image==0.16.2\n",
            "scikit-learn==0.22.2.post1\n",
            "scipy==1.4.1\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==2.1.3\n",
            "seaborn==0.11.1\n",
            "semver==2.13.0\n",
            "Send2Trash==1.5.0\n",
            "setuptools-git==1.2\n",
            "Shapely==1.7.1\n",
            "simplegeneric==0.8.1\n",
            "six==1.15.0\n",
            "sklearn==0.0\n",
            "sklearn-pandas==1.8.0\n",
            "smart-open==5.0.0\n",
            "snowballstemmer==2.1.0\n",
            "sortedcontainers==2.4.0\n",
            "SoundFile==0.10.3.post1\n",
            "spacy==2.2.4\n",
            "Sphinx==1.8.5\n",
            "sphinxcontrib-serializinghtml==1.1.4\n",
            "sphinxcontrib-websupport==1.2.4\n",
            "SQLAlchemy==1.4.15\n",
            "sqlparse==0.4.1\n",
            "srsly==1.0.5\n",
            "statsmodels==0.10.2\n",
            "sympy==1.7.1\n",
            "tables==3.4.4\n",
            "tabulate==0.8.9\n",
            "tblib==1.7.0\n",
            "tensorboard==2.5.0\n",
            "tensorboard-data-server==0.6.1\n",
            "tensorboard-plugin-wit==1.8.0\n",
            "tensorflow==2.5.0\n",
            "tensorflow-datasets==4.0.1\n",
            "tensorflow-estimator==2.5.0\n",
            "tensorflow-gcs-config==2.5.0\n",
            "tensorflow-hub==0.12.0\n",
            "tensorflow-metadata==1.0.0\n",
            "tensorflow-probability==0.12.1\n",
            "termcolor==1.1.0\n",
            "terminado==0.10.0\n",
            "testpath==0.5.0\n",
            "text-unidecode==1.3\n",
            "textblob==0.15.3\n",
            "Theano-PyMC==1.1.2\n",
            "thinc==7.4.0\n",
            "tifffile==2021.4.8\n",
            "toml==0.10.2\n",
            "toolz==0.11.1\n",
            "torch==1.8.1+cu101\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.9.1\n",
            "torchvision==0.9.1+cu101\n",
            "tornado==5.1.1\n",
            "tqdm==4.41.1\n",
            "traitlets==5.0.5\n",
            "tweepy==3.10.0\n",
            "typeguard==2.7.1\n",
            "typing-extensions==3.7.4.3\n",
            "tzlocal==1.5.1\n",
            "uritemplate==3.0.1\n",
            "urllib3==1.24.3\n",
            "vega-datasets==0.9.0\n",
            "wasabi==0.8.2\n",
            "wcwidth==0.2.5\n",
            "webencodings==0.5.1\n",
            "Werkzeug==1.0.1\n",
            "widgetsnbextension==3.5.1\n",
            "wordcloud==1.5.0\n",
            "wrapt==1.12.1\n",
            "xarray==0.18.2\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.1.0\n",
            "xlwt==1.3.0\n",
            "yellowbrick==0.9.1\n",
            "zict==2.0.0\n",
            "zipp==3.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5paWqo7tWL2"
      },
      "source": [
        "## Policy Gradient\n",
        "\n",
        "現在來搭建一個簡單的 policy network。\n",
        "我們預設模型的輸入是 8-dim 的 observation，輸出則是離散的四個動作之一："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8tdmeD-tZew"
      },
      "source": [
        "class PolicyGradientNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(PolicyGradientNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(8, 32)\n",
        "        self.fc2 = nn.Linear(32, 64)\n",
        "        self.fc3 = nn.Linear(64, 4)\n",
        "        self.acf = nn.ReLU()\n",
        "\n",
        "    def forward(self, state):\n",
        "        hid = self.acf(self.fc1(state))\n",
        "        hid = self.acf(self.fc2(hid))\n",
        "        return F.softmax(self.fc3(hid), dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1mUbulXDkZ3"
      },
      "source": [
        "class Critic(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Critic, self).__init__()\n",
        "        self.fc1 = nn.Linear(8, 32)\n",
        "        self.fc2 = nn.Linear(32, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "        self.acf = nn.ReLU()\n",
        "\n",
        "    def forward(self, state):\n",
        "        value = self.acf(self.fc1(state))\n",
        "        value = self.acf(self.fc2(value))\n",
        "        value = self.fc3(value)\n",
        "        return value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynbqJrhIFTC3"
      },
      "source": [
        "再來，搭建一個簡單的 agent，並搭配上方的 policy network 來採取行動。\n",
        "這個 agent 能做到以下幾件事：\n",
        "- `learn()`：從記下來的 log probabilities 及 rewards 來更新 policy network。\n",
        "- `sample()`：從 environment 得到 observation 之後，利用 policy network 得出應該採取的行動。\n",
        "而此函式除了回傳抽樣出來的 action，也會回傳此次抽樣的 log probabilities。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZo-IxJx286z"
      },
      "source": [
        "\n",
        "class PolicyGradientAgent():\n",
        "    \n",
        "    def __init__(self, actor, critic):\n",
        "        self.actor = actor\n",
        "        self.critic = critic\n",
        "        self.optimizerA = optim.Adam(self.actor.parameters(), lr=0.001)\n",
        "        self.optimizerC = optim.Adam(self.critic.parameters(), lr=0.001)\n",
        "         \n",
        "    def forward(self, state):\n",
        "        return self.actor(state), self.critic(state)\n",
        "\n",
        "    def judge(self, state):\n",
        "        state = torch.FloatTensor(state)\n",
        "        return self.critic(state)\n",
        "\n",
        "    def learn(self, log_probs, returns, values):\n",
        "        values = values.view(-1)\n",
        "        advantage = returns - values\n",
        "        loss_actor = -(log_probs * advantage.detach()).sum() \n",
        "        loss_critic = advantage.pow(2).sum()\n",
        "\n",
        "        self.optimizerA.zero_grad()\n",
        "        self.optimizerC.zero_grad()\n",
        "        loss_actor.backward()\n",
        "        loss_critic.backward()\n",
        "        self.optimizerA.step()\n",
        "        self.optimizerC.step()\n",
        "        \n",
        "    def sample(self, state):\n",
        "        action_prob = self.actor(torch.FloatTensor(state))\n",
        "        action_dist = Categorical(action_prob)\n",
        "        action = action_dist.sample()\n",
        "        log_prob = action_dist.log_prob(action)\n",
        "        return action.item(), log_prob\n",
        "\n",
        "    def save(self, PATH): # You should not revise this\n",
        "        Agent_Dict = {\n",
        "            \"network\" : self.actor.state_dict(),\n",
        "            \"optimizer\" : self.optimizer.state_dict()\n",
        "        }\n",
        "        torch.save(Agent_Dict, PATH)\n",
        "\n",
        "    def load(self, PATH): # You should not revise this\n",
        "        checkpoint = torch.load(PATH)\n",
        "        self.actor.load_state_dict(checkpoint[\"network\"])\n",
        "        #如果要儲存過程或是中斷訓練後想繼續可以用喔 ^_^\n",
        "        self.optimizer.load_state_dict(checkpoint[\"optimizer\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehPlnTKyRZf9"
      },
      "source": [
        "最後，建立一個 network 和 agent，就可以開始進行訓練了。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t-JsKxUViFy"
      },
      "source": [
        "def evaluate(agent):\n",
        "  fix(env, seed)\n",
        "  agent.actor.eval()  \n",
        "  NUM_OF_TEST = 5 \n",
        "  test_total_reward = []\n",
        "  action_list = []\n",
        "  for i in range(NUM_OF_TEST):\n",
        "    actions = []\n",
        "    state = env.reset()\n",
        "\n",
        "    total_reward = 0\n",
        "\n",
        "    done = False\n",
        "    while not done:\n",
        "        action, _ = agent.sample(state)\n",
        "        actions.append(action)\n",
        "        state, reward, done, _ = env.step(action)\n",
        "\n",
        "        total_reward += reward\n",
        "\n",
        "    #print(total_reward)\n",
        "    test_total_reward.append(total_reward)\n",
        "\n",
        "    action_list.append(actions) #儲存你測試的結果\n",
        "    \n",
        "  agent.actor.train()\n",
        "\n",
        "  return np.mean(test_total_reward), action_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfJIvML-RYjL"
      },
      "source": [
        "actor = PolicyGradientNetwork()\n",
        "critic = Critic()\n",
        "agent = PolicyGradientAgent(actor,critic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouv23glgf5Qt"
      },
      "source": [
        "## 訓練 Agent\n",
        "\n",
        "現在我們開始訓練 agent。\n",
        "透過讓 agent 和 environment 互動，我們記住每一組對應的 log probabilities 及 reward，並在成功登陸或者不幸墜毀後，回放這些「記憶」來訓練 policy network。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "92fd902784d3400ab9f1c6b94df238a2",
            "d1b7a3d6ae2646548dbdd3483b6d4762",
            "4752da1585a24067ba964b63901ea25c",
            "3ee4860615ac4fd79e1efa86646dc8c3",
            "ffc1d8fa701641649855bfc2c98015ef",
            "de5eea0fe42c48d3b25e3399a8c155e0",
            "7bc941b2f719490e9ad1c5fdd5e4d6ff",
            "1b14adfaf93e44a8b2b2b5e3c667d93b"
          ]
        },
        "id": "vg5rxBBaf38_",
        "outputId": "ac358eae-0aee-4bfe-d791-ee40d4ec98ba"
      },
      "source": [
        "agent.actor.train()  \n",
        "agent.critic.train()\n",
        "\n",
        "EPISODE_PER_BATCH = 1  \n",
        "NUM_BATCH = 3500       \n",
        "factor = 0.995\n",
        "avg_total_rewards, avg_final_rewards = [], []\n",
        "best_score = 0\n",
        "best_action = None\n",
        "prg_bar = tqdm(range(NUM_BATCH))\n",
        "for batch in prg_bar:\n",
        "\n",
        "    log_probs, rewards, values = [], [], []\n",
        "    total_rewards, final_rewards = [], []\n",
        "\n",
        "    # 蒐集訓練資料\n",
        "    for episode in range(EPISODE_PER_BATCH):\n",
        "        \n",
        "        state = env.reset()\n",
        "        total_reward, total_step = 0, 0\n",
        "        seq_rewards = []\n",
        "        while True:\n",
        "\n",
        "            action, log_prob = agent.sample(state) # at , log(at|st)\n",
        "            value = agent.judge(state)\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "            log_probs.append(log_prob) # [log(a1|s1), log(a2|s2), ...., log(at|st)]\n",
        "            # seq_rewards.append(reward)\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "            total_step += 1\n",
        "            seq_rewards.append(reward) \n",
        "            values.append(value)\n",
        "            # ! 重要 ！\n",
        "            # 現在的reward 的implementation 為每個時刻的瞬時reward, 給定action_list : a1, a2, a3 ......\n",
        "            #                                                       reward :     r1, r2 ,r3 ......\n",
        "            # medium：將reward調整成accumulative decaying reward, 給定action_list : a1,                         a2,                           a3 ......\n",
        "            #                                                       reward :     r1+0.99*r2+0.99^2*r3+......, r2+0.99*r3+0.99^2*r4+...... ,r3+0.99*r4+0.99^2*r5+ ......\n",
        "            # boss : implement DQN\n",
        "            if done:\n",
        "                final_rewards.append(reward)\n",
        "                total_rewards.append(total_reward)\n",
        "                returns = []\n",
        "                R = 0\n",
        "                for r in reversed(seq_rewards):\n",
        "                  R = r + factor*R\n",
        "                  returns.insert(0,R)\n",
        "\n",
        "                rewards.extend(returns)\n",
        "\n",
        "                break  \n",
        "    # 紀錄訓練過程\n",
        "    avg_total_reward = sum(total_rewards) / len(total_rewards)\n",
        "    avg_final_reward = sum(final_rewards) / len(final_rewards)\n",
        "    avg_total_rewards.append(avg_total_reward)\n",
        "    avg_final_rewards.append(avg_final_reward)\n",
        "    prg_bar.set_description(f\"Total: {avg_total_reward: 4.1f}, Final: {avg_final_reward: 4.1f}\")\n",
        "\n",
        "    # 更新網路\n",
        "    # rewards = np.concatenate(rewards, axis=0)\n",
        "    rewards = (rewards - np.mean(rewards)) / (np.std(rewards) + 1e-9)  # 將 reward 正規標準化\n",
        "    agent.learn(torch.stack(log_probs), torch.from_numpy(rewards), torch.stack(values))\n",
        "    if batch%50 == 0 or batch > (NUM_BATCH - 500):\n",
        "      score, action_list = evaluate(agent)\n",
        "      print('evaluate rewards:{:.3f}'.format(score))\n",
        "      if score > best_score:\n",
        "        best_score = score\n",
        "        best_action = action_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92fd902784d3400ab9f1c6b94df238a2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=3500.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/__init__.py:422: UserWarning: torch.set_deterministic is deprecated and will be removed in a future release. Please use torch.use_deterministic_algorithms instead\n",
            "  \"torch.set_deterministic is deprecated and will be removed in a future \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "evaluate rewards:-172.633\n",
            "evaluate rewards:-201.915\n",
            "evaluate rewards:-172.008\n",
            "evaluate rewards:-262.426\n",
            "evaluate rewards:-109.850\n",
            "evaluate rewards:-155.914\n",
            "evaluate rewards:-120.599\n",
            "evaluate rewards:-52.092\n",
            "evaluate rewards:-67.520\n",
            "evaluate rewards:-95.555\n",
            "evaluate rewards:-8.634\n",
            "evaluate rewards:-19.093\n",
            "evaluate rewards:-3.725\n",
            "evaluate rewards:-0.528\n",
            "evaluate rewards:-12.259\n",
            "evaluate rewards:12.339\n",
            "evaluate rewards:38.991\n",
            "evaluate rewards:59.917\n",
            "evaluate rewards:93.172\n",
            "evaluate rewards:86.087\n",
            "evaluate rewards:13.140\n",
            "evaluate rewards:119.171\n",
            "evaluate rewards:105.839\n",
            "evaluate rewards:64.369\n",
            "evaluate rewards:104.317\n",
            "evaluate rewards:130.320\n",
            "evaluate rewards:-32.339\n",
            "evaluate rewards:190.369\n",
            "evaluate rewards:74.979\n",
            "evaluate rewards:97.671\n",
            "evaluate rewards:210.208\n",
            "evaluate rewards:138.985\n",
            "evaluate rewards:44.461\n",
            "evaluate rewards:121.353\n",
            "evaluate rewards:132.188\n",
            "evaluate rewards:114.038\n",
            "evaluate rewards:137.030\n",
            "evaluate rewards:143.598\n",
            "evaluate rewards:103.937\n",
            "evaluate rewards:117.429\n",
            "evaluate rewards:135.039\n",
            "evaluate rewards:67.811\n",
            "evaluate rewards:123.280\n",
            "evaluate rewards:139.557\n",
            "evaluate rewards:146.938\n",
            "evaluate rewards:48.900\n",
            "evaluate rewards:140.875\n",
            "evaluate rewards:134.503\n",
            "evaluate rewards:148.331\n",
            "evaluate rewards:143.833\n",
            "evaluate rewards:145.895\n",
            "evaluate rewards:153.408\n",
            "evaluate rewards:146.209\n",
            "evaluate rewards:154.647\n",
            "evaluate rewards:230.046\n",
            "evaluate rewards:194.017\n",
            "evaluate rewards:202.600\n",
            "evaluate rewards:187.202\n",
            "evaluate rewards:222.506\n",
            "evaluate rewards:274.563\n",
            "evaluate rewards:178.529\n",
            "evaluate rewards:267.529\n",
            "evaluate rewards:221.313\n",
            "evaluate rewards:198.241\n",
            "evaluate rewards:213.809\n",
            "evaluate rewards:223.323\n",
            "evaluate rewards:227.162\n",
            "evaluate rewards:133.580\n",
            "evaluate rewards:192.353\n",
            "evaluate rewards:222.658\n",
            "evaluate rewards:215.672\n",
            "evaluate rewards:200.260\n",
            "evaluate rewards:217.819\n",
            "evaluate rewards:169.929\n",
            "evaluate rewards:216.287\n",
            "evaluate rewards:167.357\n",
            "evaluate rewards:211.510\n",
            "evaluate rewards:274.134\n",
            "evaluate rewards:272.169\n",
            "evaluate rewards:267.168\n",
            "evaluate rewards:200.152\n",
            "evaluate rewards:235.023\n",
            "evaluate rewards:235.023\n",
            "evaluate rewards:235.023\n",
            "evaluate rewards:235.023\n",
            "evaluate rewards:234.331\n",
            "evaluate rewards:268.696\n",
            "evaluate rewards:208.982\n",
            "evaluate rewards:206.759\n",
            "evaluate rewards:222.219\n",
            "evaluate rewards:244.670\n",
            "evaluate rewards:261.961\n",
            "evaluate rewards:270.838\n",
            "evaluate rewards:178.525\n",
            "evaluate rewards:234.885\n",
            "evaluate rewards:273.130\n",
            "evaluate rewards:270.921\n",
            "evaluate rewards:230.060\n",
            "evaluate rewards:269.178\n",
            "evaluate rewards:206.300\n",
            "evaluate rewards:259.960\n",
            "evaluate rewards:172.215\n",
            "evaluate rewards:275.862\n",
            "evaluate rewards:250.429\n",
            "evaluate rewards:267.675\n",
            "evaluate rewards:242.089\n",
            "evaluate rewards:261.870\n",
            "evaluate rewards:241.652\n",
            "evaluate rewards:271.391\n",
            "evaluate rewards:270.249\n",
            "evaluate rewards:218.371\n",
            "evaluate rewards:246.442\n",
            "evaluate rewards:249.640\n",
            "evaluate rewards:264.340\n",
            "evaluate rewards:253.290\n",
            "evaluate rewards:260.898\n",
            "evaluate rewards:239.182\n",
            "evaluate rewards:257.014\n",
            "evaluate rewards:261.285\n",
            "evaluate rewards:258.980\n",
            "evaluate rewards:245.767\n",
            "evaluate rewards:223.609\n",
            "evaluate rewards:251.551\n",
            "evaluate rewards:254.783\n",
            "evaluate rewards:265.335\n",
            "evaluate rewards:260.375\n",
            "evaluate rewards:210.290\n",
            "evaluate rewards:260.569\n",
            "evaluate rewards:271.926\n",
            "evaluate rewards:265.804\n",
            "evaluate rewards:251.150\n",
            "evaluate rewards:254.133\n",
            "evaluate rewards:210.714\n",
            "evaluate rewards:271.910\n",
            "evaluate rewards:225.843\n",
            "evaluate rewards:278.679\n",
            "evaluate rewards:275.363\n",
            "evaluate rewards:231.134\n",
            "evaluate rewards:220.654\n",
            "evaluate rewards:214.664\n",
            "evaluate rewards:260.073\n",
            "evaluate rewards:274.096\n",
            "evaluate rewards:276.801\n",
            "evaluate rewards:223.417\n",
            "evaluate rewards:175.917\n",
            "evaluate rewards:261.643\n",
            "evaluate rewards:267.813\n",
            "evaluate rewards:272.265\n",
            "evaluate rewards:266.642\n",
            "evaluate rewards:272.218\n",
            "evaluate rewards:272.297\n",
            "evaluate rewards:269.840\n",
            "evaluate rewards:236.162\n",
            "evaluate rewards:270.151\n",
            "evaluate rewards:270.140\n",
            "evaluate rewards:224.190\n",
            "evaluate rewards:273.318\n",
            "evaluate rewards:217.672\n",
            "evaluate rewards:268.844\n",
            "evaluate rewards:229.170\n",
            "evaluate rewards:255.808\n",
            "evaluate rewards:251.932\n",
            "evaluate rewards:251.661\n",
            "evaluate rewards:259.615\n",
            "evaluate rewards:269.875\n",
            "evaluate rewards:255.520\n",
            "evaluate rewards:261.856\n",
            "evaluate rewards:240.283\n",
            "evaluate rewards:238.891\n",
            "evaluate rewards:263.455\n",
            "evaluate rewards:276.141\n",
            "evaluate rewards:262.712\n",
            "evaluate rewards:263.515\n",
            "evaluate rewards:252.075\n",
            "evaluate rewards:251.163\n",
            "evaluate rewards:251.163\n",
            "evaluate rewards:203.698\n",
            "evaluate rewards:233.884\n",
            "evaluate rewards:252.345\n",
            "evaluate rewards:252.345\n",
            "evaluate rewards:196.565\n",
            "evaluate rewards:210.809\n",
            "evaluate rewards:273.589\n",
            "evaluate rewards:259.701\n",
            "evaluate rewards:254.912\n",
            "evaluate rewards:251.514\n",
            "evaluate rewards:252.888\n",
            "evaluate rewards:243.949\n",
            "evaluate rewards:252.033\n",
            "evaluate rewards:250.027\n",
            "evaluate rewards:257.487\n",
            "evaluate rewards:269.256\n",
            "evaluate rewards:252.468\n",
            "evaluate rewards:271.298\n",
            "evaluate rewards:253.302\n",
            "evaluate rewards:256.534\n",
            "evaluate rewards:237.714\n",
            "evaluate rewards:242.800\n",
            "evaluate rewards:257.014\n",
            "evaluate rewards:265.981\n",
            "evaluate rewards:254.661\n",
            "evaluate rewards:264.335\n",
            "evaluate rewards:263.144\n",
            "evaluate rewards:267.914\n",
            "evaluate rewards:204.051\n",
            "evaluate rewards:264.871\n",
            "evaluate rewards:250.007\n",
            "evaluate rewards:244.629\n",
            "evaluate rewards:271.220\n",
            "evaluate rewards:261.390\n",
            "evaluate rewards:266.300\n",
            "evaluate rewards:223.965\n",
            "evaluate rewards:227.987\n",
            "evaluate rewards:270.656\n",
            "evaluate rewards:262.461\n",
            "evaluate rewards:278.393\n",
            "evaluate rewards:227.331\n",
            "evaluate rewards:240.419\n",
            "evaluate rewards:203.796\n",
            "evaluate rewards:184.831\n",
            "evaluate rewards:221.827\n",
            "evaluate rewards:212.404\n",
            "evaluate rewards:271.522\n",
            "evaluate rewards:272.154\n",
            "evaluate rewards:218.576\n",
            "evaluate rewards:217.862\n",
            "evaluate rewards:218.121\n",
            "evaluate rewards:235.469\n",
            "evaluate rewards:270.321\n",
            "evaluate rewards:280.020\n",
            "evaluate rewards:265.757\n",
            "evaluate rewards:264.965\n",
            "evaluate rewards:266.972\n",
            "evaluate rewards:260.837\n",
            "evaluate rewards:218.031\n",
            "evaluate rewards:265.325\n",
            "evaluate rewards:218.172\n",
            "evaluate rewards:218.561\n",
            "evaluate rewards:252.324\n",
            "evaluate rewards:254.882\n",
            "evaluate rewards:267.749\n",
            "evaluate rewards:266.854\n",
            "evaluate rewards:261.327\n",
            "evaluate rewards:220.673\n",
            "evaluate rewards:248.190\n",
            "evaluate rewards:253.530\n",
            "evaluate rewards:188.745\n",
            "evaluate rewards:226.247\n",
            "evaluate rewards:269.143\n",
            "evaluate rewards:253.880\n",
            "evaluate rewards:265.731\n",
            "evaluate rewards:264.924\n",
            "evaluate rewards:245.781\n",
            "evaluate rewards:261.059\n",
            "evaluate rewards:243.612\n",
            "evaluate rewards:239.506\n",
            "evaluate rewards:268.878\n",
            "evaluate rewards:249.534\n",
            "evaluate rewards:256.164\n",
            "evaluate rewards:257.107\n",
            "evaluate rewards:138.849\n",
            "evaluate rewards:228.412\n",
            "evaluate rewards:186.858\n",
            "evaluate rewards:198.334\n",
            "evaluate rewards:173.046\n",
            "evaluate rewards:214.930\n",
            "evaluate rewards:204.574\n",
            "evaluate rewards:201.062\n",
            "evaluate rewards:214.712\n",
            "evaluate rewards:203.665\n",
            "evaluate rewards:221.851\n",
            "evaluate rewards:194.880\n",
            "evaluate rewards:172.936\n",
            "evaluate rewards:256.450\n",
            "evaluate rewards:169.108\n",
            "evaluate rewards:198.034\n",
            "evaluate rewards:258.710\n",
            "evaluate rewards:220.520\n",
            "evaluate rewards:234.932\n",
            "evaluate rewards:192.455\n",
            "evaluate rewards:214.149\n",
            "evaluate rewards:197.022\n",
            "evaluate rewards:243.910\n",
            "evaluate rewards:208.954\n",
            "evaluate rewards:146.348\n",
            "evaluate rewards:275.296\n",
            "evaluate rewards:207.331\n",
            "evaluate rewards:197.152\n",
            "evaluate rewards:254.668\n",
            "evaluate rewards:177.968\n",
            "evaluate rewards:247.511\n",
            "evaluate rewards:251.988\n",
            "evaluate rewards:247.628\n",
            "evaluate rewards:205.073\n",
            "evaluate rewards:267.324\n",
            "evaluate rewards:218.946\n",
            "evaluate rewards:211.477\n",
            "evaluate rewards:139.466\n",
            "evaluate rewards:255.090\n",
            "evaluate rewards:249.423\n",
            "evaluate rewards:268.103\n",
            "evaluate rewards:180.013\n",
            "evaluate rewards:165.749\n",
            "evaluate rewards:221.629\n",
            "evaluate rewards:221.291\n",
            "evaluate rewards:252.350\n",
            "evaluate rewards:185.305\n",
            "evaluate rewards:217.605\n",
            "evaluate rewards:142.822\n",
            "evaluate rewards:275.381\n",
            "evaluate rewards:201.987\n",
            "evaluate rewards:139.440\n",
            "evaluate rewards:264.847\n",
            "evaluate rewards:268.814\n",
            "evaluate rewards:227.417\n",
            "evaluate rewards:217.796\n",
            "evaluate rewards:197.665\n",
            "evaluate rewards:191.273\n",
            "evaluate rewards:222.454\n",
            "evaluate rewards:191.179\n",
            "evaluate rewards:264.825\n",
            "evaluate rewards:273.935\n",
            "evaluate rewards:231.748\n",
            "evaluate rewards:273.144\n",
            "evaluate rewards:271.947\n",
            "evaluate rewards:198.697\n",
            "evaluate rewards:184.854\n",
            "evaluate rewards:268.422\n",
            "evaluate rewards:213.551\n",
            "evaluate rewards:238.108\n",
            "evaluate rewards:212.487\n",
            "evaluate rewards:243.803\n",
            "evaluate rewards:248.891\n",
            "evaluate rewards:208.663\n",
            "evaluate rewards:204.276\n",
            "evaluate rewards:158.454\n",
            "evaluate rewards:201.518\n",
            "evaluate rewards:187.792\n",
            "evaluate rewards:181.914\n",
            "evaluate rewards:221.839\n",
            "evaluate rewards:186.988\n",
            "evaluate rewards:229.630\n",
            "evaluate rewards:227.807\n",
            "evaluate rewards:237.434\n",
            "evaluate rewards:262.834\n",
            "evaluate rewards:180.926\n",
            "evaluate rewards:201.973\n",
            "evaluate rewards:258.342\n",
            "evaluate rewards:204.331\n",
            "evaluate rewards:154.371\n",
            "evaluate rewards:203.214\n",
            "evaluate rewards:118.528\n",
            "evaluate rewards:159.177\n",
            "evaluate rewards:176.319\n",
            "evaluate rewards:160.899\n",
            "evaluate rewards:136.399\n",
            "evaluate rewards:175.858\n",
            "evaluate rewards:156.995\n",
            "evaluate rewards:259.869\n",
            "evaluate rewards:89.213\n",
            "evaluate rewards:243.163\n",
            "evaluate rewards:208.461\n",
            "evaluate rewards:267.045\n",
            "evaluate rewards:108.137\n",
            "evaluate rewards:222.962\n",
            "evaluate rewards:188.010\n",
            "evaluate rewards:175.138\n",
            "evaluate rewards:53.098\n",
            "evaluate rewards:152.736\n",
            "evaluate rewards:162.237\n",
            "evaluate rewards:189.600\n",
            "evaluate rewards:137.299\n",
            "evaluate rewards:154.720\n",
            "evaluate rewards:154.720\n",
            "evaluate rewards:154.738\n",
            "evaluate rewards:174.171\n",
            "evaluate rewards:131.802\n",
            "evaluate rewards:100.327\n",
            "evaluate rewards:112.488\n",
            "evaluate rewards:134.020\n",
            "evaluate rewards:233.452\n",
            "evaluate rewards:184.782\n",
            "evaluate rewards:169.309\n",
            "evaluate rewards:258.073\n",
            "evaluate rewards:125.175\n",
            "evaluate rewards:264.761\n",
            "evaluate rewards:199.364\n",
            "evaluate rewards:167.709\n",
            "evaluate rewards:217.470\n",
            "evaluate rewards:265.522\n",
            "evaluate rewards:245.361\n",
            "evaluate rewards:252.053\n",
            "evaluate rewards:132.419\n",
            "evaluate rewards:262.978\n",
            "evaluate rewards:259.117\n",
            "evaluate rewards:212.303\n",
            "evaluate rewards:219.687\n",
            "evaluate rewards:264.195\n",
            "evaluate rewards:266.545\n",
            "evaluate rewards:258.359\n",
            "evaluate rewards:266.001\n",
            "evaluate rewards:257.949\n",
            "evaluate rewards:244.253\n",
            "evaluate rewards:196.194\n",
            "evaluate rewards:248.578\n",
            "evaluate rewards:240.037\n",
            "evaluate rewards:233.235\n",
            "evaluate rewards:265.174\n",
            "evaluate rewards:254.694\n",
            "evaluate rewards:263.507\n",
            "evaluate rewards:252.252\n",
            "evaluate rewards:261.368\n",
            "evaluate rewards:257.108\n",
            "evaluate rewards:212.405\n",
            "evaluate rewards:260.717\n",
            "evaluate rewards:271.176\n",
            "evaluate rewards:220.143\n",
            "evaluate rewards:216.148\n",
            "evaluate rewards:242.045\n",
            "evaluate rewards:248.665\n",
            "evaluate rewards:163.686\n",
            "evaluate rewards:164.981\n",
            "evaluate rewards:259.150\n",
            "evaluate rewards:212.403\n",
            "evaluate rewards:267.150\n",
            "evaluate rewards:245.528\n",
            "evaluate rewards:198.073\n",
            "evaluate rewards:138.088\n",
            "evaluate rewards:198.432\n",
            "evaluate rewards:222.426\n",
            "evaluate rewards:169.342\n",
            "evaluate rewards:210.144\n",
            "evaluate rewards:253.051\n",
            "evaluate rewards:202.050\n",
            "evaluate rewards:263.732\n",
            "evaluate rewards:206.534\n",
            "evaluate rewards:257.560\n",
            "evaluate rewards:244.794\n",
            "evaluate rewards:258.276\n",
            "evaluate rewards:191.568\n",
            "evaluate rewards:254.159\n",
            "evaluate rewards:184.606\n",
            "evaluate rewards:256.184\n",
            "evaluate rewards:269.903\n",
            "evaluate rewards:257.701\n",
            "evaluate rewards:236.837\n",
            "evaluate rewards:250.477\n",
            "evaluate rewards:219.464\n",
            "evaluate rewards:256.779\n",
            "evaluate rewards:199.192\n",
            "evaluate rewards:264.352\n",
            "evaluate rewards:250.832\n",
            "evaluate rewards:245.273\n",
            "evaluate rewards:241.929\n",
            "evaluate rewards:221.104\n",
            "evaluate rewards:250.129\n",
            "evaluate rewards:230.352\n",
            "evaluate rewards:246.629\n",
            "evaluate rewards:254.886\n",
            "evaluate rewards:233.856\n",
            "evaluate rewards:238.949\n",
            "evaluate rewards:242.807\n",
            "evaluate rewards:257.662\n",
            "evaluate rewards:202.756\n",
            "evaluate rewards:244.749\n",
            "evaluate rewards:234.441\n",
            "evaluate rewards:249.242\n",
            "evaluate rewards:256.113\n",
            "evaluate rewards:197.944\n",
            "evaluate rewards:239.518\n",
            "evaluate rewards:251.571\n",
            "evaluate rewards:245.818\n",
            "evaluate rewards:262.031\n",
            "evaluate rewards:259.304\n",
            "evaluate rewards:258.765\n",
            "evaluate rewards:219.720\n",
            "evaluate rewards:244.294\n",
            "evaluate rewards:219.571\n",
            "evaluate rewards:252.033\n",
            "evaluate rewards:260.658\n",
            "evaluate rewards:263.001\n",
            "evaluate rewards:263.698\n",
            "evaluate rewards:265.323\n",
            "evaluate rewards:254.006\n",
            "evaluate rewards:261.831\n",
            "evaluate rewards:262.118\n",
            "evaluate rewards:250.690\n",
            "evaluate rewards:258.366\n",
            "evaluate rewards:247.283\n",
            "evaluate rewards:226.975\n",
            "evaluate rewards:271.970\n",
            "evaluate rewards:257.869\n",
            "evaluate rewards:199.259\n",
            "evaluate rewards:260.688\n",
            "evaluate rewards:189.222\n",
            "evaluate rewards:248.770\n",
            "evaluate rewards:242.452\n",
            "evaluate rewards:234.338\n",
            "evaluate rewards:235.385\n",
            "evaluate rewards:251.532\n",
            "evaluate rewards:248.961\n",
            "evaluate rewards:249.124\n",
            "evaluate rewards:228.251\n",
            "evaluate rewards:257.680\n",
            "evaluate rewards:254.912\n",
            "evaluate rewards:252.717\n",
            "evaluate rewards:260.206\n",
            "evaluate rewards:261.531\n",
            "evaluate rewards:261.380\n",
            "evaluate rewards:248.048\n",
            "evaluate rewards:196.552\n",
            "evaluate rewards:280.051\n",
            "evaluate rewards:250.802\n",
            "evaluate rewards:265.525\n",
            "evaluate rewards:250.065\n",
            "evaluate rewards:187.424\n",
            "evaluate rewards:258.833\n",
            "evaluate rewards:270.973\n",
            "evaluate rewards:249.943\n",
            "evaluate rewards:139.113\n",
            "evaluate rewards:197.923\n",
            "evaluate rewards:214.424\n",
            "evaluate rewards:194.014\n",
            "evaluate rewards:229.179\n",
            "evaluate rewards:274.407\n",
            "evaluate rewards:235.319\n",
            "evaluate rewards:274.980\n",
            "evaluate rewards:254.428\n",
            "evaluate rewards:185.864\n",
            "evaluate rewards:222.003\n",
            "evaluate rewards:275.681\n",
            "evaluate rewards:266.411\n",
            "evaluate rewards:147.863\n",
            "evaluate rewards:266.713\n",
            "evaluate rewards:212.155\n",
            "evaluate rewards:211.019\n",
            "evaluate rewards:205.224\n",
            "evaluate rewards:245.121\n",
            "evaluate rewards:209.166\n",
            "evaluate rewards:199.606\n",
            "evaluate rewards:200.107\n",
            "evaluate rewards:268.703\n",
            "evaluate rewards:169.419\n",
            "evaluate rewards:265.508\n",
            "evaluate rewards:209.234\n",
            "evaluate rewards:274.229\n",
            "evaluate rewards:269.568\n",
            "evaluate rewards:258.472\n",
            "evaluate rewards:261.224\n",
            "evaluate rewards:268.594\n",
            "evaluate rewards:276.841\n",
            "evaluate rewards:113.011\n",
            "evaluate rewards:117.232\n",
            "evaluate rewards:190.400\n",
            "evaluate rewards:262.745\n",
            "evaluate rewards:260.015\n",
            "evaluate rewards:266.830\n",
            "evaluate rewards:256.939\n",
            "evaluate rewards:256.604\n",
            "evaluate rewards:193.931\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7sTaA61fqjD",
        "outputId": "bf7d45e2-346c-457b-d8a3-e9d9cac1ba1e"
      },
      "source": [
        "best_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "280.0508555974373"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzGybqQMMgJa",
        "outputId": "9cdc4a35-b8be-485e-e365-808388debd78"
      },
      "source": [
        "print('best score:',best_score)\n",
        "PATH = \"Action_List_test.npy\" \n",
        "np.save(PATH ,np.array(best_action)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNb_tuFYhKVK"
      },
      "source": [
        "### 訓練結果\n",
        "\n",
        "訓練過程中，我們持續記下了 `avg_total_reward`，這個數值代表的是：每次更新 policy network 前，我們讓 agent 玩數個回合（episodes），而這些回合的平均 total rewards 為何。\n",
        "理論上，若是 agent 一直在進步，則所得到的 `avg_total_reward` 也會持續上升，直至 250 上下。\n",
        "若將其畫出來則結果如下："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "wZYOI8H10SHN",
        "outputId": "57e9082e-04cd-4043-d18a-46b6e05bb811"
      },
      "source": [
        "end = time.time()\n",
        "plt.plot(avg_total_rewards)\n",
        "plt.title(\"Total Rewards\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV5jj4dThz0Y"
      },
      "source": [
        "另外，`avg_final_reward` 代表的是多個回合的平均 final rewards，而 final reward 即是 agent 在單一回合中拿到的最後一個 reward。\n",
        "如果同學們還記得環境給予登月小艇 reward 的方式，便會知道，不論**回合的最後**小艇是不幸墜毀、飛出畫面、或是靜止在地面上，都會受到額外地獎勵或處罰。\n",
        "也因此，final reward 可被用來觀察 agent 的「著地」是否順利等資訊。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "txDZ5vlGWz5w",
        "outputId": "db80e0b4-4f94-442f-f70c-22c525653429"
      },
      "source": [
        "plt.plot(avg_final_rewards)\n",
        "plt.title(\"Final Rewards\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyT7tNwkVdS-"
      },
      "source": [
        "訓練時間\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2HaGRVEYGQS"
      },
      "source": [
        "## 測試"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yFuUKKRYH73"
      },
      "source": [
        "fix(env, seed)\n",
        "agent.actor.eval()  # 測試前先將 network 切換為 evaluation 模式\n",
        "NUM_OF_TEST = 5 # Do not revise it !!!!!\n",
        "test_total_reward = []\n",
        "action_list = []\n",
        "for i in range(NUM_OF_TEST):\n",
        "  actions = []\n",
        "  state = env.reset()\n",
        "\n",
        "  img = plt.imshow(env.render(mode='rgb_array'))\n",
        "\n",
        "  total_reward = 0\n",
        "\n",
        "  done = False\n",
        "  while not done:\n",
        "      action, _ = agent.sample(state)\n",
        "      actions.append(action)\n",
        "      state, reward, done, _ = env.step(action)\n",
        "\n",
        "      total_reward += reward\n",
        "\n",
        "      #img.set_data(env.render(mode='rgb_array'))\n",
        "      #display.display(plt.gcf())\n",
        "      #display.clear_output(wait=True)\n",
        "  print(total_reward)\n",
        "  test_total_reward.append(total_reward)\n",
        "\n",
        "  action_list.append(actions) #儲存你測試的結果\n",
        "  print(\"length of actions is \", len(actions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aex7mcKr0J01"
      },
      "source": [
        "print(f\"Your final reward is : %.2f\"%np.mean(test_total_reward))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leyebGYRpqsF"
      },
      "source": [
        "Action list 的長相"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGAH4YWDpp4u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "717d444b-4896-4b79-f64a-34fb58b5acc9"
      },
      "source": [
        "print(\"Action list looks like \", action_list)\n",
        "print(\"Action list's shape looks like \", np.shape(action_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Action list looks like  [[1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 0, 1, 2, 3, 3, 1, 2, 3, 2, 3, 0, 2, 2, 3, 3, 2, 3, 2, 2, 2, 0, 3, 3, 2, 2, 3, 2, 2, 3, 2, 2, 1, 2, 3, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 3, 2, 2, 3, 2, 2, 2, 1, 2, 2, 3, 3, 3, 1, 2, 2, 2, 2, 2, 3, 3, 2, 2, 1, 3, 2, 1, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 1, 3, 1, 1, 2, 2, 2, 1, 3, 2, 2, 2, 1, 1, 3, 2, 2, 2, 2, 2, 1, 3, 1, 2, 3, 2, 2, 2, 1, 1, 2, 3, 2, 2, 1, 2, 2, 2, 0, 3, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2, 2, 2, 1, 1, 1, 2, 0, 1, 2, 2, 2, 0, 3, 2, 3, 3, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 1, 0, 2, 1, 2, 2, 1, 3, 2, 2, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 3, 0, 0, 3, 0, 0, 1, 3, 2, 2, 0, 2, 1, 3, 2, 2, 3, 2, 2, 2, 0, 1, 2, 1, 2, 1, 2, 2, 2, 2, 3, 2, 2, 3, 1, 3, 1, 1, 3, 3, 2, 3, 2, 1, 2, 2, 2, 1, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 3, 1, 2, 2, 2, 2, 2, 3, 2, 1, 1, 1, 2, 2, 2, 2, 3, 3, 2, 2, 2, 3, 2, 2, 2, 2, 1, 3, 2, 3, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 1, 2, 2, 3, 2, 2, 3, 2, 3, 2, 2, 2, 3, 2, 2, 1, 2, 2, 2, 2, 1, 3, 1, 1, 2, 2, 2, 0, 2, 3, 2, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 3, 3, 1, 1, 2, 2, 3, 2, 3, 3, 2, 2, 2, 2, 3, 2, 2, 3, 3, 3, 2, 1, 3, 2, 2, 2, 2, 2, 1, 2, 3, 3, 2, 2, 1, 1, 2, 1, 2, 1, 3, 2, 2, 1, 2, 0, 3, 2, 3, 3, 3, 2, 3, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 3, 2, 2, 3, 3, 2, 2, 2, 2, 3, 1, 2, 2, 2, 3, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 3, 2, 2, 0, 2, 3, 2, 1, 1, 2, 1, 2, 2, 2, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 0, 2, 1, 1, 3, 1, 1, 2, 3, 3, 3, 2, 2, 1, 2, 2, 2, 2, 3, 3, 2, 0, 2, 3, 1, 3, 2, 3, 2, 2, 1, 2, 2, 2, 2, 2, 3, 1, 2, 0, 2, 2, 2, 2, 3, 2, 2, 2, 0, 2, 0, 1, 2, 2, 2, 2, 3, 1, 3, 2, 1, 2, 2, 1, 2, 3, 3, 1, 2, 2, 2, 2, 2, 2, 3, 1, 2, 2, 2, 2, 3, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 3, 2, 1, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 1, 2, 3, 3, 3, 2, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 3, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 1, 2, 2, 2, 3, 1, 1, 3, 3, 2, 2, 3, 2, 1, 1, 3, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 3, 2, 3, 3, 2, 2, 2, 3, 2, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 2, 2, 3, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 2, 3, 1, 2, 3, 2, 2, 2, 2, 2, 1, 1, 2, 2, 3, 2, 2, 2, 3, 2, 3, 2, 3, 2, 2, 1, 2, 1, 2, 2, 3, 2, 2, 1, 1, 2, 2, 2, 2, 0, 2, 1, 2, 3, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 3, 2, 2, 2, 1, 2, 3, 2, 1, 3, 2, 0, 3, 3, 0, 2, 1, 2, 2, 1, 2, 2, 2, 3, 2, 2, 2, 1, 1, 3, 2, 2, 2, 3, 2, 2, 3, 2, 3, 2, 1, 1, 3, 2, 2, 2, 3, 3, 2, 1, 2, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 0, 2, 2, 1, 3, 3, 2, 2, 2, 2, 2, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "Action list's shape looks like  (5,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7sokqEUtrFY"
      },
      "source": [
        "Action 的分布\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHdAItjj1nxw"
      },
      "source": [
        "distribution = {}\n",
        "for actions in action_list:\n",
        "  for action in actions:\n",
        "    if action not in distribution.keys():\n",
        "      distribution[action] = 1\n",
        "    else:\n",
        "      distribution[action] += 1\n",
        "print(distribution)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ricE0schY75M"
      },
      "source": [
        "儲存 Model Testing的結果\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZsMkGmIY42b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "350d68e3-61e5-4c42-f3ac-8818312121e3"
      },
      "source": [
        "PATH = \"Action_List_test.npy\" # 可以改成你想取的名字或路徑\n",
        "np.save(PATH ,np.array(action_list)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUBtYXG2eaqf"
      },
      "source": [
        "## 參考資料\n",
        "\n",
        "以下是一些有用的參考資料。\n",
        "建議同學們實做前，可以先參考第一則連結的上課影片。\n",
        "在影片的最後有提到兩個有用的 Tips，這對於本次作業的實做非常有幫助。\n",
        "\n",
        "- [DRL Lecture 1: Policy Gradient (Review)](https://youtu.be/z95ZYgPgXOY)\n",
        "- [ML Lecture 23-3: Reinforcement Learning (including Q-learning) start at 30:00](https://youtu.be/2-JNBzCq77c?t=1800)\n",
        "- [Lecture 7: Policy Gradient, David Silver](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/pg.pdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGqP2EU1joWM"
      },
      "source": [
        ""
      ]
    }
  ]
}